{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Model | MusicGen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zIxgIvmwsyNO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ]
    },
    {
      "metadata": {
        "id": "Ap0_IxJssyNR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Importing liabraries"
      ]
    },
    {
      "metadata": {
        "id": "9lv8Qz_bsyNT",
        "colab_type": "code",
        "outputId": "54ee8860-16d6-4f4b-9a6e-18d5a744a814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import music21\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cnftnjpWsyNb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Importing notes"
      ]
    },
    {
      "metadata": {
        "id": "GgtmAgiIsyNe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('notes.pickle', 'rb') as f:\n",
        "    notes = pickle.load(f)\n",
        "\n",
        "pitchNames = set (notes)\n",
        "nNotes = len (pitchNames)\n",
        "pitchNames = sorted (pitchNames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SQbEaNKDsyNl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Encoding notes"
      ]
    },
    {
      "metadata": {
        "id": "Z9dF5_tqsyNn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "noteCoding = {}\n",
        "\n",
        "code = 0\n",
        "for i in pitchNames :\n",
        "    noteCoding [i] = code\n",
        "    code += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cgY17-RysyNt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### One hot encoding"
      ]
    },
    {
      "metadata": {
        "id": "02y83n2lsyNv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequence = 100\n",
        "nInput = []\n",
        "nOutput = []\n",
        "\n",
        "for i in range (0, len (notes) - sequence, 1) : \n",
        "    \n",
        "    sIn = notes [i : i + sequence]\n",
        "    sOut = notes [i + sequence]\n",
        "    nInput.append ([noteCoding [c]for c in sIn])\n",
        "    nOutput.append (noteCoding [sOut])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t86_XJh9syN4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nInput = np.reshape (nInput, (len (nInput), sequence, 1))\n",
        "nInput = nInput / float (nNotes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LlMxLF48syN_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nOutput = np_utils.to_categorical(nOutput)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVesI4V8syOD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Creating model"
      ]
    },
    {
      "metadata": {
        "id": "x8zNeUmLsyOD",
        "colab_type": "code",
        "outputId": "888d9c40-67d6-4077-e029-359b7b4557af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(\n",
        "    512,\n",
        "    input_shape=(nInput.shape[1], nInput.shape[2]),\n",
        "    return_sequences=True\n",
        "))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(LSTM(512))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(nNotes))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vJfRcHINsyOH",
        "colab_type": "code",
        "outputId": "a389abb2-037c-4755-a7ab-0135df5214d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary ()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100, 512)          1052672   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100, 512)          2099200   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 358)               92006     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 358)               0         \n",
            "=================================================================\n",
            "Total params: 5,474,406\n",
            "Trainable params: 5,474,406\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4L5WcHrGsyOL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Saving weights"
      ]
    },
    {
      "metadata": {
        "id": "nMGF4CyLsyON",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath,\n",
        "    monitor='loss',\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8BwOGKhbsyOV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Training model"
      ]
    },
    {
      "metadata": {
        "id": "DgiLDXtvsyOX",
        "colab_type": "code",
        "outputId": "8b8b6ee9-725f-4222-eefc-886921924b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2468
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(nInput, nOutput, epochs = 100, batch_size = 64, callbacks = callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "57077/57077 [==============================] - 379s 7ms/step - loss: 4.7555\n",
            "Epoch 2/100\n",
            "57077/57077 [==============================] - 371s 7ms/step - loss: 4.7137\n",
            "Epoch 3/100\n",
            "57077/57077 [==============================] - 375s 7ms/step - loss: 5.2695\n",
            "Epoch 4/100\n",
            "57077/57077 [==============================] - 368s 6ms/step - loss: 4.7081\n",
            "Epoch 5/100\n",
            "57077/57077 [==============================] - 373s 7ms/step - loss: 4.7171\n",
            "Epoch 6/100\n",
            "57077/57077 [==============================] - 371s 7ms/step - loss: 4.7080\n",
            "Epoch 7/100\n",
            "57077/57077 [==============================] - 371s 7ms/step - loss: 4.7081\n",
            "Epoch 8/100\n",
            "57077/57077 [==============================] - 372s 7ms/step - loss: 4.7063\n",
            "Epoch 9/100\n",
            "57077/57077 [==============================] - 374s 7ms/step - loss: 4.7420\n",
            "Epoch 10/100\n",
            "57077/57077 [==============================] - 371s 7ms/step - loss: 4.6912\n",
            "Epoch 11/100\n",
            "57077/57077 [==============================] - 375s 7ms/step - loss: 5.0898\n",
            "Epoch 12/100\n",
            "57077/57077 [==============================] - 377s 7ms/step - loss: 4.7585\n",
            "Epoch 13/100\n",
            "57077/57077 [==============================] - 379s 7ms/step - loss: 4.7120\n",
            "Epoch 14/100\n",
            "57077/57077 [==============================] - 379s 7ms/step - loss: 4.7180\n",
            "Epoch 15/100\n",
            "57077/57077 [==============================] - 376s 7ms/step - loss: 4.7025\n",
            "Epoch 16/100\n",
            "57077/57077 [==============================] - 376s 7ms/step - loss: 4.6847\n",
            "Epoch 17/100\n",
            "57077/57077 [==============================] - 378s 7ms/step - loss: 4.6387\n",
            "Epoch 18/100\n",
            "57077/57077 [==============================] - 380s 7ms/step - loss: 4.5733\n",
            "Epoch 19/100\n",
            "57077/57077 [==============================] - 376s 7ms/step - loss: 4.5477\n",
            "Epoch 20/100\n",
            "57077/57077 [==============================] - 383s 7ms/step - loss: 4.5245\n",
            "Epoch 21/100\n",
            "57077/57077 [==============================] - 379s 7ms/step - loss: 4.4893\n",
            "Epoch 22/100\n",
            "57077/57077 [==============================] - 372s 7ms/step - loss: 4.4450\n",
            "Epoch 23/100\n",
            "57077/57077 [==============================] - 371s 7ms/step - loss: 4.3949\n",
            "Epoch 24/100\n",
            "57077/57077 [==============================] - 377s 7ms/step - loss: 4.3382\n",
            "Epoch 25/100\n",
            "57077/57077 [==============================] - 373s 7ms/step - loss: 4.2631\n",
            "Epoch 26/100\n",
            "57077/57077 [==============================] - 373s 7ms/step - loss: 4.1730\n",
            "Epoch 27/100\n",
            "57077/57077 [==============================] - 373s 7ms/step - loss: 4.0801\n",
            "Epoch 28/100\n",
            "57077/57077 [==============================] - 373s 7ms/step - loss: 3.9612\n",
            "Epoch 29/100\n",
            "57077/57077 [==============================] - 372s 7ms/step - loss: 3.8424\n",
            "Epoch 30/100\n",
            "57077/57077 [==============================] - 381s 7ms/step - loss: 3.7104\n",
            "Epoch 31/100\n",
            "57077/57077 [==============================] - 376s 7ms/step - loss: 3.5676\n",
            "Epoch 32/100\n",
            "57077/57077 [==============================] - 379s 7ms/step - loss: 3.4130\n",
            "Epoch 33/100\n",
            "57077/57077 [==============================] - 384s 7ms/step - loss: 3.2464\n",
            "Epoch 34/100\n",
            "57077/57077 [==============================] - 379s 7ms/step - loss: 3.0894\n",
            "Epoch 35/100\n",
            "57077/57077 [==============================] - 383s 7ms/step - loss: 2.9398\n",
            "Epoch 36/100\n",
            "57077/57077 [==============================] - 383s 7ms/step - loss: 2.7915\n",
            "Epoch 37/100\n",
            "57077/57077 [==============================] - 382s 7ms/step - loss: 2.6518\n",
            "Epoch 38/100\n",
            "57077/57077 [==============================] - 377s 7ms/step - loss: 2.5208\n",
            "Epoch 39/100\n",
            "57077/57077 [==============================] - 378s 7ms/step - loss: 2.3875\n",
            "Epoch 40/100\n",
            "57077/57077 [==============================] - 374s 7ms/step - loss: 2.2653\n",
            "Epoch 41/100\n",
            "57077/57077 [==============================] - 380s 7ms/step - loss: 2.1584\n",
            "Epoch 42/100\n",
            "57077/57077 [==============================] - 379s 7ms/step - loss: 2.0423\n",
            "Epoch 43/100\n",
            "57077/57077 [==============================] - 377s 7ms/step - loss: 1.9347\n",
            "Epoch 44/100\n",
            "57077/57077 [==============================] - 382s 7ms/step - loss: 1.8337\n",
            "Epoch 45/100\n",
            "57077/57077 [==============================] - 380s 7ms/step - loss: 1.7549\n",
            "Epoch 46/100\n",
            "57077/57077 [==============================] - 380s 7ms/step - loss: 1.6684\n",
            "Epoch 47/100\n",
            "57077/57077 [==============================] - 380s 7ms/step - loss: 1.5896\n",
            "Epoch 48/100\n",
            "57077/57077 [==============================] - 377s 7ms/step - loss: 1.5116\n",
            "Epoch 49/100\n",
            "57077/57077 [==============================] - 377s 7ms/step - loss: 1.4486\n",
            "Epoch 50/100\n",
            "57077/57077 [==============================] - 380s 7ms/step - loss: 1.3830\n",
            "Epoch 51/100\n",
            "57077/57077 [==============================] - 379s 7ms/step - loss: 1.3165\n",
            "Epoch 52/100\n",
            "57077/57077 [==============================] - 374s 7ms/step - loss: 1.2534\n",
            "Epoch 53/100\n",
            "57077/57077 [==============================] - 416s 7ms/step - loss: 1.1981\n",
            "Epoch 54/100\n",
            "57077/57077 [==============================] - 383s 7ms/step - loss: 1.1548\n",
            "Epoch 55/100\n",
            "57077/57077 [==============================] - 376s 7ms/step - loss: 1.1104\n",
            "Epoch 56/100\n",
            "57077/57077 [==============================] - 376s 7ms/step - loss: 1.0649\n",
            "Epoch 57/100\n",
            "57077/57077 [==============================] - 374s 7ms/step - loss: 1.0272\n",
            "Epoch 58/100\n",
            "57077/57077 [==============================] - 375s 7ms/step - loss: 0.9914\n",
            "Epoch 59/100\n",
            "57077/57077 [==============================] - 378s 7ms/step - loss: 0.9555\n",
            "Epoch 60/100\n",
            "57077/57077 [==============================] - 375s 7ms/step - loss: 0.9302\n",
            "Epoch 61/100\n",
            "57077/57077 [==============================] - 374s 7ms/step - loss: 0.9068\n",
            "Epoch 62/100\n",
            "57077/57077 [==============================] - 380s 7ms/step - loss: 0.8742\n",
            "Epoch 63/100\n",
            "57077/57077 [==============================] - 379s 7ms/step - loss: 0.8493\n",
            "Epoch 64/100\n",
            "57077/57077 [==============================] - 377s 7ms/step - loss: 0.8293\n",
            "Epoch 65/100\n",
            "57077/57077 [==============================] - 374s 7ms/step - loss: 0.8071\n",
            "Epoch 66/100\n",
            "57077/57077 [==============================] - 373s 7ms/step - loss: 0.7842\n",
            "Epoch 67/100\n",
            "57077/57077 [==============================] - 374s 7ms/step - loss: 0.7679\n",
            "Epoch 68/100\n",
            "57077/57077 [==============================] - 377s 7ms/step - loss: 0.7498\n",
            "Epoch 69/100\n",
            "57077/57077 [==============================] - 377s 7ms/step - loss: 0.7378\n",
            "Epoch 70/100\n",
            " 1728/57077 [..............................] - ETA: 6:34 - loss: 0.5984Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MxpJqnmRsyOb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Model trained"
      ]
    }
  ]
}